{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and \n",
    "# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md\n",
    "\n",
    "model = SentenceTransformer('bert-large-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files read:  119\n"
     ]
    }
   ],
   "source": [
    "# # This section reads from the files, encodes the content into vectors\n",
    "\n",
    "import os\n",
    "directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP\\\\text_files\\\\current'''\n",
    "# directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP'''\n",
    "# directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\enron_mail_20150507\\\\bigger emails'''\n",
    "\n",
    "# list to store content and names\n",
    "fileContents = []\n",
    "fileNames = [] \n",
    "\n",
    "# count = 0\n",
    "for file in os.listdir(directory):\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         print(\"File: \", os.path.join(directory, file))\n",
    "    fileNames.append(os.path.join(directory, file))\n",
    "\n",
    "    # read in the contents of the file\n",
    "    f = open(os.path.join(directory, file), \"r\", encoding=\"utf8\")\n",
    "    fileContent = f.read()\n",
    "#     if len(fileContent)> 8000:\n",
    "# #         print(len(fileContent))\n",
    "#         fileContent = fileContent[:8000]\n",
    "#         count += 1\n",
    "    fileContents.append(fileContent)\n",
    "    f.close()\n",
    "# print(\"Files above 8000: \", count)\n",
    "\n",
    "print(\"Number of files read: \", len(fileNames))\n",
    "\n",
    "# # Each sentence is encoded as a 1-D vector with 768 columns\n",
    "sentences = fileContents\n",
    "# sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "\n",
    "# print('Sample BERT embedding vector - length', len(sentence_embeddings[0]))\n",
    "\n",
    "# print('Sample BERT embedding vector - note includes negative values', sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  02-05-machine-learning-update-6718980..txt\n",
      "Name:  02-05-machine-learning-update-6718980.txt\n",
      "Name:  20201015 OML Introduction and Roadmap..txt\n",
      "Name:  20201015 OML Introduction and Roadmap.txt\n",
      "Name:  4 Steps of RPA Implementation with Process Mining..txt\n",
      "Name:  4 Steps of RPA Implementation with Process Mining.txt\n",
      "Name:  Accenture-A-How-Insurers-Can-Make-the-Most-of-Robotic-Process-Automation-PoV..txt\n",
      "Name:  Accenture-A-How-Insurers-Can-Make-the-Most-of-Robotic-Process-Automation-PoV.txt\n",
      "Name:  Accenture-AI-Robotic-Process-Automation-Video-Transcript..txt\n",
      "Name:  Accenture-AI-Robotic-Process-Automation-Video-Transcript.txt\n",
      "Name:  Accenture-Gearing-Towards-Intelligent-Automation..txt\n",
      "Name:  Accenture-Gearing-Towards-Intelligent-Automation.txt\n",
      "Name:  Accenture-Machine-Leaning-Insurance..txt\n",
      "Name:  Accenture-Machine-Leaning-Insurance.txt\n",
      "Name:  Accenture-Robotic-Process-Auto-POV..txt\n",
      "Name:  Accenture-Robotic-Process-Auto-POV.txt\n",
      "Name:  Accenture-Robotics-Process-Automation-Capital-Markets..txt\n",
      "Name:  Accenture-Robotics-Process-Automation-Capital-Markets.txt\n",
      "Name:  ai-at-work-ebook..txt\n",
      "Name:  ai-at-work-ebook.txt\n",
      "Name:  BCG-Are-You-Spending-Enough-on-Cybersecurity-Feb-2019_tcm93-214372..txt\n",
      "Name:  BCG-Are-You-Spending-Enough-on-Cybersecurity-Feb-2019_tcm93-214372.txt\n",
      "Name:  BCG-Artificial-Intelligence-Is-a-Threat-to-Cyber-Security-Its-Also-a-Solution-Nov-2018_tcm9-207468..txt\n",
      "Name:  BCG-Artificial-Intelligence-Is-a-Threat-to-Cyber-Security-Its-Also-a-Solution-Nov-2018_tcm9-207468.txt\n",
      "Name:  BCG-Building-a-Cyberresilient-Organization-Jan-2017_tcm9-186244..txt\n",
      "Name:  BCG-Building-a-Cyberresilient-Organization-Jan-2017_tcm9-186244.txt\n",
      "Name:  BCG-Building-the-Cyberresilient-Health-Care-Organization-Dec-2017_tcm9-179303..txt\n",
      "Name:  BCG-Building-the-Cyberresilient-Health-Care-Organization-Dec-2017_tcm9-179303.txt\n",
      "Name:  BCG_Cybersecurity_Meets_IT_Risk_Mgmt_Oct_2014_R_tcm9-206983..txt\n",
      "Name:  BCG_Cybersecurity_Meets_IT_Risk_Mgmt_Oct_2014_R_tcm9-206983.txt\n",
      "Name:  ca-en-cyber-risk-services..txt\n",
      "Name:  ca-en-cyber-risk-services.txt\n",
      "Name:  cybersecurity-nist-k12-brochure..txt\n",
      "Name:  cybersecurity-nist-k12-brochure.txt\n",
      "Name:  cyberstrategyoptimizationforriskmanagement-bcgplatinion..txt\n",
      "Name:  cyberstrategyoptimizationforriskmanagement-bcgplatinion.txt\n",
      "Name:  D1_1000_Cyrille Bataller_Accenture v2..txt\n",
      "Name:  D1_1000_Cyrille Bataller_Accenture v2.txt\n",
      "Name:  dcs-brochure-2008..txt\n",
      "Name:  dcs-brochure-2008.txt\n",
      "Name:  Dell-SMB-Designed-WhitePaper-First-Draft-30-04-2018-revised..txt\n",
      "Name:  Dell-SMB-Designed-WhitePaper-First-Draft-30-04-2018-revised.txt\n",
      "Name:  Dell-Technologies-Ready-for-Artificial-Intelligence-By-Moor-Insights-And-Strategy..txt\n",
      "Name:  Dell-Technologies-Ready-for-Artificial-Intelligence-By-Moor-Insights-And-Strategy.txt\n",
      "Name:  dell_cybersecurity_context..txt\n",
      "Name:  dell_cybersecurity_context.txt\n",
      "Name:  deloitte-uk-matt-stallard-erp-and-enabling-technologies..txt\n",
      "Name:  deloitte-uk-matt-stallard-erp-and-enabling-technologies.txt\n",
      "Name:  Digital transformation- seven steps to success.v2..txt\n",
      "Name:  Digital transformation- seven steps to success.v2.txt\n",
      "Name:  digital-transformation-playbook..txt\n",
      "Name:  digital-transformation-playbook.txt\n",
      "Name:  Digital-Transformation-study-March-2018..txt\n",
      "Name:  Digital-Transformation-study-March-2018.txt\n",
      "Name:  digital_transformation_guide_2017..txt\n",
      "Name:  digital_transformation_guide_2017.txt\n",
      "Name:  disruptive-trends-technology..txt\n",
      "Name:  disruptive-trends-technology.txt\n",
      "Name:  DI_path-to-growth..txt\n",
      "Name:  DI_path-to-growth.txt\n",
      "Name:  DI_Tech-Trends-2020_Executive-summary..txt\n",
      "Name:  DI_Tech-Trends-2020_Executive-summary.txt\n",
      "Name:  dynamics365-en-conversation-ray-wang..txt\n",
      "Name:  dynamics365-en-conversation-ray-wang.txt\n",
      "Name:  dynamics365-en-digital-transformation..txt\n",
      "Name:  dynamics365-en-digital-transformation.txt\n",
      "Name:  EN-Accelerating Digital Transformation With Technology-en-us..txt\n",
      "Name:  EN-Accelerating Digital Transformation With Technology-en-us.txt\n",
      "Name:  FederalCybersecurityServices-KPMG..txt\n",
      "Name:  FederalCybersecurityServices-KPMG.txt\n",
      "Name:  ffeic-view-on-cyber..txt\n",
      "Name:  ffeic-view-on-cyber.txt\n",
      "Name:  gx-enterprise-technology-and-performance..txt\n",
      "Name:  gx-enterprise-technology-and-performance.txt\n",
      "Name:  gx-ers-cyber-security-everybodys-imperative..txt\n",
      "Name:  gx-ers-cyber-security-everybodys-imperative.txt\n",
      "Name:  gx-tech-trends-2020-overview-booklet..txt\n",
      "Name:  gx-tech-trends-2020-overview-booklet.txt\n",
      "Name:  h17605-artificial-intelligence-consulting-services..txt\n",
      "Name:  h17605-artificial-intelligence-consulting-services.txt\n",
      "Name:  Hexaware-Role_of_AI&RPA_in_transforming_Banking_Operations_v9..txt\n",
      "Name:  Hexaware-Role_of_AI&RPA_in_transforming_Banking_Operations_v9.txt\n",
      "Name:  journey-cloud-hied..txt\n",
      "Name:  journey-cloud-hied.txt\n",
      "Name:  JP-Morgan-tech-strategy.txt\n",
      "Name:  leveraging-power-ai-and-robotics..txt\n",
      "Name:  leveraging-power-ai-and-robotics.txt\n",
      "Name:  Leveraging-Technology-Thrive-Transformative-Period-Caltech-White-Paper_B-FINAL-ADA..txt\n",
      "Name:  Leveraging-Technology-Thrive-Transformative-Period-Caltech-White-Paper_B-FINAL-ADA.txt\n",
      "Name:  lu-technology-services..txt\n",
      "Name:  lu-technology-services.txt\n",
      "Name:  NetConferencingWebExReserved_NetCustomerDeck_240215..txt\n",
      "Name:  NetConferencingWebExReserved_NetCustomerDeck_240215.txt\n",
      "Name:  oracle_forensics_101..txt\n",
      "Name:  oracle_forensics_101.txt\n",
      "Name:  Partner_Services_Storage_Overview.p.txt\n",
      "Name:  Partner_Services_Storage_Overview.ptxt\n",
      "Name:  pwc-software-robotics..txt\n",
      "Name:  pwc-software-robotics.txt\n",
      "Name:  pwc-tax-function-of-the-future-focus-on-today-robotics-process-automation..txt\n",
      "Name:  pwc-tax-function-of-the-future-focus-on-today-robotics-process-automation.txt\n",
      "Name:  PwC_Monte Titoli_3 aprile_v8 (1)..txt\n",
      "Name:  PwC_Monte Titoli_3 aprile_v8 (1).txt\n",
      "Name:  Risk-Cyber-Intelligence-Center-A-new-approach-to-Cyber-Security-Juni-2017..txt\n",
      "Name:  Risk-Cyber-Intelligence-Center-A-new-approach-to-Cyber-Security-Juni-2017.txt\n",
      "Name:  robotic-process-automation-rpa..txt\n",
      "Name:  robotic-process-automation-rpa.txt\n",
      "Name:  Show Slides_CIO Summit Monaco_Vic Opening.p.txt\n",
      "Name:  Show Slides_CIO Summit Monaco_Vic Opening.ptxt\n",
      "Name:  the-five-most-common-cyber-security-mistakes-en..txt\n",
      "Name:  the-five-most-common-cyber-security-mistakes-en.txt\n",
      "Name:  the-future-of-it..txt\n",
      "Name:  the-future-of-it.txt\n",
      "Name:  Transforming companies must put cyber security front and center kpmg..txt\n",
      "Name:  Transforming companies must put cyber security front and center kpmg.txt\n",
      "Name:  Tribridge-Dynamics365Playbook..txt\n",
      "Name:  Tribridge-Dynamics365Playbook.txt\n",
      "Name:  Whitepaper_Gieom-Intelligence-Operations-in-Banking..txt\n",
      "Name:  Whitepaper_Gieom-Intelligence-Operations-in-Banking.txt\n"
     ]
    }
   ],
   "source": [
    "import django\n",
    "import os.path\n",
    "\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'rest.settings')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "django.setup()\n",
    "\n",
    "from docs.models import docs\n",
    "# from emails.models import emails\n",
    "\n",
    "all_docs = docs.objects.all()\n",
    "# This section reads from the files, encodes the content into vectors\n",
    "\n",
    "# import os\n",
    "directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP\\\\text_files\\\\current'''\n",
    "# directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP'''\n",
    "\n",
    "# # list to store content and names\n",
    "# fileContents = []\n",
    "# fileNames = []\n",
    "\n",
    "# print(model.encode(fileContents[0]).size)\n",
    "# input the docs into the database\n",
    "count = 0\n",
    "for i in range(len(fileContents)):\n",
    "    foundCount = 0\n",
    "    path_of_file = fileNames[i]\n",
    "    name_of_file = os.path.basename(path_of_file)\n",
    "    for doc in all_docs:\n",
    "        if doc.document_name == name_of_file:\n",
    "            foundCount = 1\n",
    "            break\n",
    "    if foundCount == 0:\n",
    "        embedding = model.encode(fileContents[i]).tobytes()\n",
    "        new_doc = docs(document_name=name_of_file, embeddings=embedding, text_file=path_of_file)\n",
    "        new_doc.save()\n",
    "        print(\"Name: \", name_of_file)\n",
    "# notFoundCount = len(fileContents) - count\n",
    "# print(\"Count: \", count)\n",
    "    \n",
    "\n",
    "# all_docs = docs.objects.all()\n",
    "# print(all_docs[0].document_name)\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(vars(all_docs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets individual embedded vectors and creates a np array of embedded vectors\n",
    "\n",
    "all_docs = docs.objects.all()\n",
    "\n",
    "extracted_embeddings = []\n",
    "fileNames = []\n",
    "for doc in all_docs:\n",
    "    extracted_embedding = np.frombuffer(doc.embeddings, dtype = \"float32\")\n",
    "    extracted_embeddings.append(extracted_embedding)\n",
    "    fileNames.append(doc.document_name)\n",
    "\n",
    "extracted_embeddings = np.array(extracted_embeddings) \n",
    "# print(\"Equal? \", np.array_equal(sentence_embeddings, extracted_embeddings))\n",
    "\n",
    "# cursor.execute(\"\"\"SELECT * FROM t1\"\"\")\n",
    "\n",
    "# row = cursor.fetchone()\n",
    "\n",
    "# extracted_embeddings = []\n",
    "# for row in cursor:\n",
    "#     extracted_embedding = np.frombuffer(row[2], dtype = \"float32\")\n",
    "#     extracted_embeddings.append(extracted_embedding)\n",
    "\n",
    "# extracted_embeddings = np.array(extracted_embeddings) \n",
    "# print(\"Equal? \", np.array_equal(sentence_embeddings, extracted_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search Results\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: email regarding meeting with governor\n",
      "\n",
      "Top 5:\n",
      "allen-p_604 (Cosine Score: 0.7018)\n",
      "badeer-r_62 (Cosine Score: 0.6459)\n",
      "badeer-r_299 (Cosine Score: 0.6361)\n",
      "badeer-r_18 (Cosine Score: 0.6355)\n",
      "bass-e_431 (Cosine Score: 0.6321)\n",
      "badeer-r_197 (Cosine Score: 0.6304)\n",
      "badeer-r_71 (Cosine Score: 0.6282)\n",
      "bass-e_718 (Cosine Score: 0.6262)\n",
      "arnold-j_136 (Cosine Score: 0.6229)\n",
      "bass-e_590 (Cosine Score: 0.6204)\n"
     ]
    }
   ],
   "source": [
    "# search using a query\n",
    "import scipy\n",
    "\n",
    "#@title Sematic Search Form\n",
    "\n",
    "\n",
    "query = 'email regarding meeting with governor' #@param {type: 'string'}\n",
    "\n",
    "queries = [query]\n",
    "query_embeddings = model.encode(queries)\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "number_top_matches = 10 #@param {type: \"number\"}\n",
    "\n",
    "print(\"Semantic Search Results\")\n",
    "\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], extracted_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5:\")\n",
    "\n",
    "    for idx, distance in results[0:number_top_matches]:\n",
    "#         content = sentences[idx]\n",
    "        print(fileNames[idx], \"(Cosine Score: %.4f)\" % (1-distance))\n",
    "#         print(sentences[idx], \"(Cosine Score: %.4f)\" % (1-distance))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files read:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\enron_mail_20150507\\\\bigger emails'''\n",
    "# directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP'''\n",
    "\n",
    "# list to store content and names\n",
    "fileContents = []\n",
    "fileNames = [] \n",
    "\n",
    "# count = 0\n",
    "for file in os.listdir(directory):\n",
    "    if not file.endswith(\".txt\"):\n",
    "#         print(\"File: \", os.path.join(directory, file))\n",
    "#     fileNames.append(os.path.join(directory, file))\n",
    "\n",
    "#     # read in the contents of the file\n",
    "#     f = open(os.path.join(directory, file), \"r\", encoding=\"utf8\")\n",
    "#     fileContent = f.read()\n",
    "#     if len(fileContent)> 8000:\n",
    "# #             print(len(fileContent))\n",
    "#         fileContent = fileContent[:8000]\n",
    "# #             count += 1\n",
    "#     fileContents.append(fileContent)\n",
    "#     f.close()\n",
    "        os.rename(os.path.join(directory, file), os.path.join(directory, file+\".txt\"))\n",
    "# print(\"Files above 8000: \", count)\n",
    "\n",
    "print(\"Number of files read: \", len(fileNames))\n",
    "\n",
    "# # Each sentence is encoded as a 1-D vector with 768 columns\n",
    "sentences = fileContents\n",
    "# sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "\n",
    "# print('Sample BERT embedding vector - length', len(sentence_embeddings[0]))\n",
    "\n",
    "# print('Sample BERT embedding vector - note includes negative values', sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # change the names of the emails to account for the person\n",
    "# # sending or receiving the names to avoid name collision\n",
    "# import os\n",
    "# directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\enron_mail_20150507\\\\change'''\n",
    "\n",
    "# # list to store content and names\n",
    "# original_directories = os.listdir(directory)\n",
    "# print(original_directories)\n",
    "# # count = 0\n",
    "# for file in original_directories:\n",
    "#     print(file)\n",
    "#     file_path = os.path.join(directory, file)\n",
    "#     if os.path.isdir(file_path):\n",
    "#         print(\"Found directory: \", file)\n",
    "#         docDir = os.path.join(file_path, \"all_documents\")\n",
    "#         for email in os.listdir(docDir):\n",
    "#             old_name = os.path.join(docDir, email)\n",
    "# #             print(\"File:\", email)\n",
    "#             new_name = os.path.join(docDir, file + \"_\" + email)\n",
    "#             os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful for dividing annual reports into sections\n",
    "\n",
    "# from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    " \n",
    "# pdf_file_path = 'D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP\\\\annual_reports\\\\NASDAQ_AGYS_2015.pdf'\n",
    "# file_base_name = pdf_file_path.replace('.pdf', '')\n",
    " \n",
    "# pdf = PdfFileReader(pdf_file_path)\n",
    "# dst = 'share-based compensation' \n",
    "# pages = [65,66,67,68] # page 1, 3, 5,,\n",
    "# pdfWriter = PdfFileWriter()\n",
    " \n",
    "# for page_num in pages:\n",
    "#     pdfWriter.addPage(pdf.getPage(page_num))\n",
    " \n",
    "# with open('{0}_{1}.pdf'.format(file_base_name, dst), 'wb') as f:\n",
    "#     pdfWriter.write(f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the database in csv for later use when the model is changed\n",
    "all_docs = docs.objects.all()\n",
    "path = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP'''\n",
    "path = os.path.join(path, \"bert-large-db.txt\")\n",
    "csv_string = ''\n",
    "for doc in all_docs:\n",
    "    csv_string += '{0},{1},{2};'.format(doc.document_name, doc.embeddings, doc.text_file)\n",
    "    \n",
    "text_file = open(path, \"w\")\n",
    "text_file.write(csv_string)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some files from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-05-machine-learning-update-6718980..txt\n",
      "02-05-machine-learning-update-6718980.txt\n",
      "2019-etudecgmit19..txt\n",
      "2019-etudecgmit19.txt\n",
      "20201015 OML Introduction and Roadmap..txt\n",
      "20201015 OML Introduction and Roadmap.txt\n",
      "4 Steps of RPA Implementation with Process Mining..txt\n",
      "4 Steps of RPA Implementation with Process Mining.txt\n",
      "Accenture-A-How-Insurers-Can-Make-the-Most-of-Robotic-Process-Automation-PoV..txt\n",
      "Accenture-A-How-Insurers-Can-Make-the-Most-of-Robotic-Process-Automation-PoV.txt\n",
      "Accenture-AI-Robotic-Process-Automation-Video-Transcript..txt\n",
      "Accenture-AI-Robotic-Process-Automation-Video-Transcript.txt\n",
      "Accenture-Digital-Process-Automation..txt\n",
      "Accenture-Digital-Process-Automation.txt\n",
      "Accenture-Emerging-Trends-Validation-Machine-Learning-AI-Models..txt\n",
      "Accenture-Emerging-Trends-Validation-Machine-Learning-AI-Models.txt\n",
      "Accenture-Financial-Services-AI-Neural-Networks-PoV..txt\n",
      "Accenture-Financial-Services-AI-Neural-Networks-PoV.txt\n",
      "Accenture-Future-Systems-Report..txt\n",
      "Accenture-Future-Systems-Report.txt\n",
      "Accenture-Gearing-Towards-Intelligent-Automation..txt\n",
      "Accenture-Gearing-Towards-Intelligent-Automation.txt\n",
      "accenture-industrializes-machine-learning-workloads-on-aws..txt\n",
      "accenture-industrializes-machine-learning-workloads-on-aws.txt\n",
      "Accenture-Industry-XO-whitepaper..txt\n",
      "Accenture-Industry-XO-whitepaper.txt\n",
      "Accenture-Machine-Leaning-Insurance..txt\n",
      "Accenture-Machine-Leaning-Insurance.txt\n",
      "Accenture-Robotic-Process-Auto-POV..txt\n",
      "Accenture-Robotic-Process-Auto-POV.txt\n",
      "Accenture-Robotics-Process-Automation-Capital-Markets..txt\n",
      "Accenture-Robotics-Process-Automation-Capital-Markets.txt\n",
      "Accenture-Tech19-12pp-Brochure..txt\n",
      "Accenture-Tech19-12pp-Brochure.txt\n",
      "Accenture-Understanding-Machines-Explainable-AI..txt\n",
      "Accenture-Understanding-Machines-Explainable-AI.txt\n",
      "ai-at-work-ebook..txt\n",
      "ai-at-work-ebook.txt\n",
      "AI_in_Management_Report..txt\n",
      "AI_in_Management_Report.txt\n",
      "BCG-AI-in-the-Factory-of-the-Future-Apr-2018_tcm9-188726..txt\n",
      "BCG-AI-in-the-Factory-of-the-Future-Apr-2018_tcm9-188726.txt\n",
      "BCG-Are-You-Spending-Enough-on-Cybersecurity-Feb-2019_tcm93-214372..txt\n",
      "BCG-Are-You-Spending-Enough-on-Cybersecurity-Feb-2019_tcm93-214372.txt\n",
      "BCG-Artificial-Intelligence-Is-a-Threat-to-Cyber-Security-Its-Also-a-Solution-Nov-2018_tcm9-207468..txt\n",
      "BCG-Artificial-Intelligence-Is-a-Threat-to-Cyber-Security-Its-Also-a-Solution-Nov-2018_tcm9-207468.txt\n",
      "BCG-Building-a-Cyberresilient-Organization-Jan-2017_tcm9-186244..txt\n",
      "BCG-Building-a-Cyberresilient-Organization-Jan-2017_tcm9-186244.txt\n",
      "BCG-Building-the-Cyberresilient-Health-Care-Organization-Dec-2017_tcm9-179303..txt\n",
      "BCG-Building-the-Cyberresilient-Health-Care-Organization-Dec-2017_tcm9-179303.txt\n",
      "BCG-Most-Innovative-Companies-Mar-2019-R2_tcm9-215836..txt\n",
      "BCG-Most-Innovative-Companies-Mar-2019-R2_tcm9-215836.txt\n",
      "BCG-Putting-Artificial-Intelligence-to-Work-Sep-2017-rev_tcm9-172052..txt\n",
      "BCG-Putting-Artificial-Intelligence-to-Work-Sep-2017-rev_tcm9-172052.txt\n",
      "BCG-Technology-Advantage-Apr-2016..txt\n",
      "BCG-Technology-Advantage-Apr-2016.txt\n",
      "BCG-Technology-Advantage-Oct-2017_tcm9-170551..txt\n",
      "BCG-Technology-Advantage-Oct-2017_tcm9-170551.txt\n",
      "BCG-The-Dawn-of-the-Deep-Tech-Ecosystem-Mar-2019..txt\n",
      "BCG-The-Dawn-of-the-Deep-Tech-Ecosystem-Mar-2019.txt\n",
      "BCG-The-Next-Frontier-in-Digital-and-AI-Transformations-Apr-2019-BHI-logo_tcm9-218257..txt\n",
      "BCG-The-Next-Frontier-in-Digital-and-AI-Transformations-Apr-2019-BHI-logo_tcm9-218257.txt\n",
      "BCG_Cybersecurity_Meets_IT_Risk_Mgmt_Oct_2014_R_tcm9-206983..txt\n",
      "BCG_Cybersecurity_Meets_IT_Risk_Mgmt_Oct_2014_R_tcm9-206983.txt\n",
      "ca-en-cyber-risk-services..txt\n",
      "ca-en-cyber-risk-services.txt\n",
      "cloud-technology-healthcare..txt\n",
      "cloud-technology-healthcare.txt\n",
      "Cognitive-Technologies..txt\n",
      "Cognitive-Technologies.txt\n",
      "cognitive_automation_ai_sdlc..txt\n",
      "cognitive_automation_ai_sdlc.txt\n",
      "Cyber Security and Insider Risk 1.17.18..txt\n",
      "Cyber Security and Insider Risk 1.17.18.txt\n",
      "cybersecurity-nist-k12-brochure..txt\n",
      "cybersecurity-nist-k12-brochure.txt\n",
      "cyberstrategyoptimizationforriskmanagement-bcgplatinion..txt\n",
      "cyberstrategyoptimizationforriskmanagement-bcgplatinion.txt\n",
      "D1_1000_Cyrille Bataller_Accenture v2..txt\n",
      "D1_1000_Cyrille Bataller_Accenture v2.txt\n",
      "dcs-brochure-2008..txt\n",
      "dcs-brochure-2008.txt\n",
      "dell-cloud-strategy-wp_es..txt\n",
      "dell-cloud-strategy-wp_es.txt\n",
      "dell-emc-ready-solutions-for-ai-and-dl..txt\n",
      "dell-emc-ready-solutions-for-ai-and-dl.txt\n",
      "Dell-SMB-Designed-WhitePaper-First-Draft-30-04-2018-revised..txt\n",
      "Dell-SMB-Designed-WhitePaper-First-Draft-30-04-2018-revised.txt\n",
      "Dell-Technologies-Ready-for-Artificial-Intelligence-By-Moor-Insights-And-Strategy..txt\n",
      "Dell-Technologies-Ready-for-Artificial-Intelligence-By-Moor-Insights-And-Strategy.txt\n",
      "dell_cybersecurity_context..txt\n",
      "dell_cybersecurity_context.txt\n",
      "deloitte-cn-cip-digital-transformation-en-170307..txt\n",
      "deloitte-cn-cip-digital-transformation-en-170307.txt\n",
      "Deloitte-Cyber-Risk-Capabilities-Broschuere..txt\n",
      "Deloitte-Cyber-Risk-Capabilities-Broschuere.txt\n",
      "deloitte-uk-matt-stallard-erp-and-enabling-technologies..txt\n",
      "deloitte-uk-matt-stallard-erp-and-enabling-technologies.txt\n",
      "deloitte-uk-world-economic-forum-artificial-intelligence-summary-report..txt\n",
      "deloitte-uk-world-economic-forum-artificial-intelligence-summary-report.txt\n",
      "Digital transformation- seven steps to success.v2..txt\n",
      "Digital transformation- seven steps to success.v2.txt\n",
      "digital-transformation-playbook..txt\n",
      "digital-transformation-playbook.txt\n",
      "Digital-Transformation-study-March-2018..txt\n",
      "Digital-Transformation-study-March-2018.txt\n",
      "digital_transformation_guide_2017..txt\n",
      "digital_transformation_guide_2017.txt\n",
      "disruptive-technology-berometer-technology-sector-report..txt\n",
      "disruptive-technology-berometer-technology-sector-report.txt\n",
      "disruptive-trends-technology..txt\n",
      "disruptive-trends-technology.txt\n",
      "DI_CIO-Insider-Reimaging-tech..txt\n",
      "DI_CIO-Insider-Reimaging-tech.txt\n",
      "DI_Convergence-of-technology..txt\n",
      "DI_Convergence-of-technology.txt\n",
      "DI_path-to-growth..txt\n",
      "DI_path-to-growth.txt\n",
      "DI_Tech-Trends-2020_Executive-summary..txt\n",
      "DI_Tech-Trends-2020_Executive-summary.txt\n",
      "DR16_cognitive_technologies..txt\n",
      "DR16_cognitive_technologies.txt\n",
      "DUP401_Exponential-Technology_vFINAL2..txt\n",
      "DUP401_Exponential-Technology_vFINAL2.txt\n",
      "dynamics365-en-conversation-ray-wang..txt\n",
      "dynamics365-en-conversation-ray-wang.txt\n",
      "dynamics365-en-digital-transformation..txt\n",
      "dynamics365-en-digital-transformation.txt\n",
      "EN-Accelerating Digital Transformation With Technology-en-us..txt\n",
      "EN-Accelerating Digital Transformation With Technology-en-us.txt\n",
      "FederalCybersecurityServices-KPMG..txt\n",
      "FederalCybersecurityServices-KPMG.txt\n",
      "ffeic-view-on-cyber..txt\n",
      "ffeic-view-on-cyber.txt\n",
      "from-tech-to-deep-tech..txt\n",
      "from-tech-to-deep-tech.txt\n",
      "gx-enterprise-technology-and-performance..txt\n",
      "gx-enterprise-technology-and-performance.txt\n",
      "gx-ers-cyber-security-everybodys-imperative..txt\n",
      "gx-ers-cyber-security-everybodys-imperative.txt\n",
      "gx-tech-trends-2020-overview-booklet..txt\n",
      "gx-tech-trends-2020-overview-booklet.txt\n",
      "h17605-artificial-intelligence-consulting-services..txt\n",
      "h17605-artificial-intelligence-consulting-services.txt\n",
      "Hexaware-Role_of_AI&RPA_in_transforming_Banking_Operations_v9..txt\n",
      "Hexaware-Role_of_AI&RPA_in_transforming_Banking_Operations_v9.txt\n",
      "in-risk-assessing-cyber-risk-noexp..txt\n",
      "in-risk-assessing-cyber-risk-noexp.txt\n",
      "isg-comment-letter-data-analytics..txt\n",
      "isg-comment-letter-data-analytics.txt\n",
      "journey-cloud-hied..txt\n",
      "journey-cloud-hied.txt\n",
      "JP-Morgan-tech-strategy.txt\n",
      "kpmg-cyber-security-catalogue-2016..txt\n",
      "kpmg-cyber-security-catalogue-2016.txt\n",
      "leveraging-power-ai-and-robotics..txt\n",
      "leveraging-power-ai-and-robotics.txt\n",
      "Leveraging-Technology-Thrive-Transformative-Period-Caltech-White-Paper_B-FINAL-ADA..txt\n",
      "Leveraging-Technology-Thrive-Transformative-Period-Caltech-White-Paper_B-FINAL-ADA.txt\n",
      "lu-technology-services..txt\n",
      "lu-technology-services.txt\n",
      "machine-learning-goes-to-the-cloud-ebook..txt\n",
      "machine-learning-goes-to-the-cloud-ebook.txt\n",
      "machine-learning-v3-4442540..txt\n",
      "machine-learning-v3-4442540.txt\n",
      "NetConferencingWebExReserved_NetCustomerDeck_240215..txt\n",
      "NetConferencingWebExReserved_NetCustomerDeck_240215.txt\n",
      "oaa122whitepaperv2-3787080..txt\n",
      "oaa122whitepaperv2-3787080.txt\n",
      "Oracle Machine Learning technical brief..txt\n",
      "Oracle Machine Learning technical brief.txt\n",
      "oracle_forensics_101..txt\n",
      "oracle_forensics_101.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partner_Services_Storage_Overview.p.txt\n",
      "Partner_Services_Storage_Overview.ptxt\n",
      "pwc-software-robotics..txt\n",
      "pwc-software-robotics.txt\n",
      "pwc-tax-function-of-the-future-focus-on-today-robotics-process-automation..txt\n",
      "pwc-tax-function-of-the-future-focus-on-today-robotics-process-automation.txt\n",
      "PwC_Monte Titoli_3 aprile_v8 (1)..txt\n",
      "PwC_Monte Titoli_3 aprile_v8 (1).txt\n",
      "Reshaping Business with Artificial Intelligence_tcm9-177882..txt\n",
      "Reshaping Business with Artificial Intelligence_tcm9-177882.txt\n",
      "Risk-Cyber-Intelligence-Center-A-new-approach-to-Cyber-Security-Juni-2017..txt\n",
      "Risk-Cyber-Intelligence-Center-A-new-approach-to-Cyber-Security-Juni-2017.txt\n",
      "robotic-process-automation-rpa..txt\n",
      "robotic-process-automation-rpa.txt\n",
      "Show Slides_CIO Summit Monaco_Vic Opening.p.txt\n",
      "Show Slides_CIO Summit Monaco_Vic Opening.ptxt\n",
      "the-five-most-common-cyber-security-mistakes-en..txt\n",
      "the-five-most-common-cyber-security-mistakes-en.txt\n",
      "the-future-of-it..txt\n",
      "the-future-of-it.txt\n",
      "Transforming companies must put cyber security front and center kpmg..txt\n",
      "Transforming companies must put cyber security front and center kpmg.txt\n",
      "Tribridge-Dynamics365Playbook..txt\n",
      "Tribridge-Dynamics365Playbook.txt\n",
      "us-jnet-2018-issue1-2-KPMG-Forbes-Digital-Transformation-report..txt\n",
      "us-jnet-2018-issue1-2-KPMG-Forbes-Digital-Transformation-report.txt\n",
      "Whitepaper_Gieom-Intelligence-Operations-in-Banking..txt\n",
      "Whitepaper_Gieom-Intelligence-Operations-in-Banking.txt\n",
      "Del :  201\n"
     ]
    }
   ],
   "source": [
    "path = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP\\\\text_files\\\\others'''\n",
    "all_docs = docs.objects.all()\n",
    "\n",
    "del_count = 0\n",
    "for doc in all_docs:\n",
    "    for file in os.listdir(path):\n",
    "        if doc.document_name == file:\n",
    "            print(doc.document_name)\n",
    "            doc.delete()\n",
    "            del_count += 1\n",
    "print(\"Del : \", del_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
