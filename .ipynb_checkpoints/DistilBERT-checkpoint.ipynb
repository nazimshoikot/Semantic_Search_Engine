{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install s3fs\n",
    "#pip install faiss\n",
    "#pip install pickle4\n",
    "#https://towardsdatascience.com/how-to-build-a-semantic-search-engine-with-transformers-and-faiss-dcbea307a0e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, model, index, num_results=10):\n",
    "    \"\"\"Tranforms query to vector using a pretrained, sentence-level \n",
    "    DistilBERT model and finds similar vectors using FAISS.\n",
    "    Args:\n",
    "        query (str): User query that should be more than a sentence long.\n",
    "        model (sentence_transformers.SentenceTransformer.SentenceTransformer)\n",
    "        index (`numpy.ndarray`): FAISS index that needs to be deserialized.\n",
    "        num_results (int): Number of results to return.\n",
    "    Returns:\n",
    "        D (:obj:`numpy.array` of `float`): Distance between results and query.\n",
    "        I (:obj:`numpy.array` of `int`): Paper ID of the results.\n",
    "    \n",
    "    \"\"\"\n",
    "    vector = model.encode(list(query))\n",
    "    D, I = index.search(np.array(vector).astype(\"float32\"), k=num_results)\n",
    "    return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def id2details(df, I, column):\n",
    "    \"\"\"Returns the paper titles based on the paper index.\"\"\"\n",
    "    return [list(df[df.id == idx][column]) for idx in I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the sentence-level DistilBERT\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files read:  1004\n"
     ]
    }
   ],
   "source": [
    "# This section reads from the files, encodes the content into vectors\n",
    "\n",
    "import os\n",
    "# directory = '''D:\\\\nazim\\\\STUDIES\\\\HKU\\\\FYP'''\n",
    "directory = './text_files/txt'\n",
    "# list to store content and names\n",
    "fileContents = []\n",
    "fileNames = [] \n",
    "\n",
    "arr =  []\n",
    "count = 0 \n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".txt\"):\n",
    "#         print(\"File: \", os.path.join(directory, file))\n",
    "        fileNames.append(os.path.join(directory, file))\n",
    "\n",
    "        # read in the contents of the file\n",
    "        f = open(os.path.join(directory, file), \"r\", encoding=\"utf8\")\n",
    "        fileContent = f.read()\n",
    "        if len(fileContent) > 10000:\n",
    "            fileContent = fileContent[:10000]\n",
    "        fileContents.append(fileContent)\n",
    "        f.close()\n",
    "        arr.append([count, file, fileContent])\n",
    "        count+=1\n",
    "\n",
    "\n",
    "# print( arr)\n",
    "print(\"Number of files read: \", len(fileContents))\n",
    "\n",
    "# # Each sentence is encoded as a 1-D vector with 768 columns\n",
    "sentences = fileContents\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "\n",
    "# print('Sample BERT embedding vector - length', len(sentence_embeddings[0]))\n",
    "\n",
    "# print('Sample BERT embedding vector - note includes negative values', sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                  Name                                            Content\n",
      "0   0   NASDAQ_WDC_1996.txt                                    WD 1996 Annu...\n",
      "1   1  NASDAQ_PANL_2017.txt                                           2017 ...\n",
      "2   2  NASDAQ_ATVI_2018.txt                                        2018 Ann...\n",
      "3   3     NYSE_VHC_2016.txt                                     TABLE OF CO...\n",
      "4   4  NASDAQ_ADBE_2010.txt                                                ...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(arr, columns = ['id','Name', 'Content']) \n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the Faiss index: 1004\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Change data type\n",
    "embeddings = np.array([embedding for embedding in sentence_embeddings]).astype(\"float32\")\n",
    "\n",
    "# Step 2: Instantiate the index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Step 3: Pass the index to IndexIDMap\n",
    "index = faiss.IndexIDMap(index)\n",
    "\n",
    "# Step 4: Add vectors and their IDs\n",
    "index.add_with_ids(embeddings, df.id.values)\n",
    "\n",
    "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Protel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [210.44383239746094, 210.6932373046875, 212.3014373779297, 224.2246551513672, 226.56423950195312, 226.76766967773438, 227.11349487304688, 228.408203125, 231.75613403320312, 233.5384521484375]\n",
      "\n",
      "MAG paper IDs: [207, 500, 151, 217, 423, 867, 345, 836, 767, 637]\n"
     ]
    }
   ],
   "source": [
    "D, I = vector_search([user_query], model, index, num_results=10)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nMAG paper IDs: {I.flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Business strategy.txt</td>\n",
       "      <td>The Company’s objective is to be the leading g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Company dividend.txt</td>\n",
       "      <td>I am delighted to welcome you as\\nshareholders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tax.txt</td>\n",
       "      <td>On October 22, 2004, the American Jobs Creatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   Name  \\\n",
       "0   0  Business strategy.txt   \n",
       "1   1   Company dividend.txt   \n",
       "2   2                tax.txt   \n",
       "\n",
       "                                             Content  \n",
       "0  The Company’s objective is to be the leading g...  \n",
       "1  I am delighted to welcome you as\\nshareholders...  \n",
       "2  On October 22, 2004, the American Jobs Creatio...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NASDAQ_VSAT_2002.txt'],\n",
       " ['NASDAQ_XLNX_2000.txt'],\n",
       " ['NASDAQ_VSAT_2001.txt'],\n",
       " ['NYSE_DOX_2002.txt'],\n",
       " ['NASDAQ_ANSS_2001.txt'],\n",
       " ['NYSE_AMT_2015.txt'],\n",
       " ['NYSE_AMD_1999.txt'],\n",
       " ['NYSE_AMT_2005.txt'],\n",
       " ['NYSE_USM_2013.txt'],\n",
       " ['NYSE_USM_1999.txt']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2details(df, I, 'Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
